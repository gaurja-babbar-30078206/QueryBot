{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINK:\n",
    "- https://www.linkedin.com/pulse/document-similarity-examples-python-rany-elhousieny-phd%E1%B4%AC%E1%B4%AE%E1%B4%B0-0i5lc#:~:text=Calculate%20cosine%20similarity%3A,the%20matrix%20(including%20itself)\n",
    "\n",
    "- https://www.linkedin.com/pulse/document-similarity-examples-python-rany-elhousieny-phd%E1%B4%AC%E1%B4%AE%E1%B4%B0-0i5lc#:~:text=Calculate%20cosine%20similarity%3A,the%20matrix%20(including%20itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSINE SIMILARITY\n",
    "- measures of distance in data mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how to implement cosine similarity?\n",
    "- I get the embedding vectors for both of them.\n",
    "- How do I seet if first of all.\n",
    "- Each response has multiple sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Similarity :\n",
    "1) Cosine similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc1 = \"The sky is blue\"\n",
    "doc2 = \"The sun is bright\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q) What is tfidfVectorizer and why should I use it?\n",
    "Q) What is tfidf score ??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the documents\n",
    "vectorizer = TfidfVectorizer()\n",
    "# vectorizer.get_feature_names_out()\n",
    "tfidf_matrix = vectorizer.fit_transform([doc1,doc2])\n",
    "# list(tfidf_matrix)\n",
    "# print(tfidf_matrix)\n",
    "# print(tfidf_matrix.getrow(0))\n",
    "print(tfidf_matrix[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I get the word embeddings\n",
    "I get an embedding vector of 768 length\n",
    "how does that work exactly ??   \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref1 = \"The different types of leave mentioned in the document are Privilege Leave (PL), Casual Leave (CL), Sick Leave (SL), Special Leave, Parental Leave (Maternity/Paternity), Sabbatical Leave, and Exit Leave.\"\n",
    "\n",
    "can1 = \"\"\"According to the document, there are several types of leave mentioned, including:\n",
    "1. Privilege Leave (PL)\n",
    "2. Casual Leave (CL)\n",
    "3. Sick Leave (SL)\n",
    "4. Special Leave (SL)\n",
    "5. Parental Leave (Maternity/Paternity)\n",
    "6. Joining/Transfer Leave\n",
    "7. Sabbatical Leave\n",
    "8. Public Holiday Leave\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# sentences = [\"The sky is blue\", \"The sky is blue\"]\n",
    "\n",
    "embeddings = embed_model.encode([ref1, can1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "np.save('embeddings.npy', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = np.load(\"embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = cosine_similarity([embeddings[0]], [embeddings[1]])\n",
    "\n",
    "print(similarity[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each candidate and reference pair, I have to create their embeddings and get theri cosine similarity value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"so I will make the answers lit from gpt\"\n",
    "\"Then one by one I will get the answers list from the model responses\"\n",
    "\"Then make embeddings one by one\"\n",
    "\n",
    "\"\"\"\n",
    "-  I have to make the embeddings of the gpt answers only once and then save it in a pickle\n",
    "- Then 9 more pickle files just to be safe ??\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to store Word vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = r\"D:\\OneDrive - Adani\\Desktop\\LEARNING_FOLDER\\_Kolkata_2024\\1_LLM\\3_Text_query_bot\\_docs\\benchmark_qa_3_temp_zero\\1+gpt35turbo+snowflake-arctic-embed-m.xlsx\"\n",
    "gpt_qa = pd.read_excel(path)\n",
    "gpt_qa[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_list = gpt_qa[\"Answers\"]\n",
    "answers_list\n",
    "\"Now make embeddings of this using a good embeddings model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## will use snowflake\n",
    "dir= r\"D:\\OneDrive - Adani\\Desktop\\LEARNING_FOLDER\\_Kolkata_2024\\1_LLM\\local_downloaded_models\\embedding_models\\snowflake-arctic-embed-m\"\n",
    "embed_llm =  HuggingFaceEmbeddings(\n",
    "            model_name = dir,\n",
    "            show_progress = True,\n",
    "            model_kwargs = {\"trust_remote_code\": True})\n",
    "\n",
    "embed_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_embeddings = embed_llm.embed_documents(answers_list)\n",
    "all_embeddings = np.array(all_embeddings)\n",
    "np.save(\"gpt_qa_embeddings.npy\", all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading the different sheets and editing\n",
    "import openpyxl\n",
    "model_file_path = r\"D:\\OneDrive - Adani\\Desktop\\LEARNING_FOLDER\\_Kolkata_2024\\1_LLM\\3_Text_query_bot\\_docs\\benchmark_qa_3_temp_zero\\llm_responses_document_query_bot.xlsx\"\n",
    "xfile = openpyxl.load_workbook(model_file_path)\n",
    "sheet_names = xfile.sheetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = xfile[sheet_names[0]]\n",
    "sheet\n",
    "\n",
    "df_sheet = pd.read_excel(model_file_path)\n",
    "df_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r\"D:\\OneDrive - Adani\\Desktop\\LEARNING_FOLDER\\_Kolkata_2024\\1_LLM\\3_Text_query_bot\\_docs\\benchmark_qa_3_temp_zero\\test.xlsx\"\n",
    "# df_sheet[\"cosine similarity\"]  = \"Hello\"\n",
    "# df_sheet.to_excel(test_path, sheet_name= sheet_names[0])\n",
    "wb2 = openpyxl.load_workbook(test_path)\n",
    "wb2.create_sheet(\"test\")\n",
    "print(wb2.sheetnames)\n",
    "sheet_names = wb2.sheetnames\n",
    "new_data = [\"Questions\", \"dfdfdf\",\"Answers\", \"cosine similarity\"]\n",
    "sheet = wb2[sheet_names[0]]\n",
    "sheet.append(new_data)\n",
    "sheet.col\n",
    "\n",
    "wb2.save(test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "now I have to make a functions\n",
    "that reads all the excel sheets\n",
    "in one loop\n",
    "it read one excel sheet\n",
    "make its individual embeddings\n",
    "and calculate its cosine similarity\n",
    "creates a cosine similarity score list of 20 questions \n",
    "and then add it to the existing file\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load embeddings list fromi\n",
    "import numpy as np\n",
    "all_ref_embeddings = np.load(\"gpt_qa_embeddings.npy\")\n",
    "len(all_ref_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "\n",
    "\n",
    "model_file_path = r\"D:\\OneDrive - Adani\\Desktop\\LEARNING_FOLDER\\_Kolkata_2024\\1_LLM\\3_Text_query_bot\\_docs\\benchmark_qa_3_temp_zero\\llm_responses_document_query_bot.xlsx\"\n",
    "wb_final = openpyxl.load_workbook(model_file_path)\n",
    "sheet_names = wb_final.sheetnames\n",
    "sheet_names\n",
    "\n",
    "\n",
    "\n",
    "def calc_cosine_sim(ref, cand):\n",
    "    print(f\"Embedding --->{cand}\")\n",
    "    print(f\" REf Embedding --->{ref}\")\n",
    "    cosine_score_list = []\n",
    "    for i in range(20):\n",
    "        score = cosine_similarity([ref[i]], [cand[i]])\n",
    "        cosine_score_list.append(score[0][0])\n",
    "    return cosine_score_list    \n",
    "        \n",
    "        \n",
    "def get_ref_embeddins():\n",
    "    return np.load(\"gpt_qa_embeddings.npy\")\n",
    "\n",
    "def init_embeddings():\n",
    "    dir= r\"D:\\OneDrive - Adani\\Desktop\\LEARNING_FOLDER\\_Kolkata_2024\\1_LLM\\local_downloaded_models\\embedding_models\\snowflake-arctic-embed-m\"\n",
    "    return  HuggingFaceEmbeddings(\n",
    "            model_name = dir,\n",
    "            show_progress = True,\n",
    "            model_kwargs = {\"trust_remote_code\": True})\n",
    "\n",
    "def edit_sheet(sheet, score):\n",
    "    for i in range(2,22):\n",
    "        sheet[f\"D{i}\"] = score[i-2]            \n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "path = r\"D:\\OneDrive - Adani\\Desktop\\LEARNING_FOLDER\\_Kolkata_2024\\1_LLM\\3_Text_query_bot\\_docs\\benchmark_qa_3_temp_zero\\llm_responses_document_query_bot.xlsx\"\n",
    "embed_llm  = init_embeddings()\n",
    "ref_embeddings = get_ref_embeddins()\n",
    "wb_final = openpyxl.load_workbook(path)\n",
    "sheet_names = wb_final.sheetnames\n",
    "\n",
    "sheet1 = wb_final[wb_final.sheetnames[0]]\n",
    "dataframe1 = pd.read_excel(path, sheet_name=wb_final.sheetnames[0])\n",
    "\n",
    "ans1 = dataframe1[\"Answers\"]\n",
    "emb1 =embed_llm.embed_documents(ans1)\n",
    "print(len(emb1))\n",
    "\n",
    "len(ref_embeddings)\n",
    "all_emb = []\n",
    "for sheet in sheet_names[:3]:\n",
    "    # print(sheets)\n",
    "    df = pd.read_excel(path, sheet_name=sheet)\n",
    "    ans = df[\"Answers\"]\n",
    "    emb = embed_llm.embed_documents(str(ans))\n",
    "    score = calc_cosine_sim(ref_embeddings, emb)\n",
    "    print(score)\n",
    "\n",
    "all_emb\n",
    "        \n",
    "\n",
    "path = r\"D:\\OneDrive - Adani\\Desktop\\LEARNING_FOLDER\\_Kolkata_2024\\1_LLM\\3_Text_query_bot\\_docs\\benchmark_qa_3_temp_zero\\llm_responses_document_query_bot.xlsx\"\n",
    "test_wb = openpyxl.load_workbook(path)\n",
    "ref_embeddings = get_ref_embeddins()\n",
    "embed_llm  = init_embeddings()\n",
    "wb_final = openpyxl.load_workbook(path)\n",
    "sheet_names = wb_final.sheetnames\n",
    "\n",
    "print(sheet_names)\n",
    "for sheet in sheet_names:\n",
    "    dataframe1 = pd.read_excel(path, sheet_name=sheet)\n",
    "    answers = dataframe1[\"Answers\"]\n",
    "    print(f\"Sheet ----> {sheet}\")\n",
    "    print(dataframe1[\"Answers\"])\n",
    "    \n",
    "    # get embeddings\n",
    "    can_embeddings = embed_llm.embed_documents(str(answers))\n",
    "    # print(can_embeddings)\n",
    "    cosine_sim_score = calc_cosine_sim(ref_embeddings, can_embeddings)\n",
    "    # print(cosine_sim_score)\n",
    "    # test_wb[sheet]\n",
    "    edit_sheet(test_wb[sheet],cosine_sim_score)\n",
    "\n",
    "test_wb.save(path)    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
